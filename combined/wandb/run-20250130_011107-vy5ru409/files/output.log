
Epoch [1/10]



Traceback (most recent call last):
  File "/notebooks/s2_multiencoder/combined/main.py", line 208, in <module>
    main()
  File "/notebooks/s2_multiencoder/combined/main.py", line 146, in main
    best_ckpt = train_dual_encoder_probe(
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/s2_multiencoder/combined/train.py", line 68, in train_dual_encoder_probe
    for clip_imgs, dino_imgs, labels in train_pbar:
  File "/usr/local/lib/python3.11/dist-packages/tqdm/std.py", line 1182, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py", line 674, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/notebooks/s2_multiencoder/combined/dataset.py", line 155, in __getitem__
    clip_enc = self.clip_processor(images=img, return_tensors="pt")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/transformers/image_processing_utils.py", line 549, in __call__
    return self.preprocess(images, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/transformers/models/clip/image_processing_clip.py", line 282, in preprocess
    images = [to_numpy_array(image) for image in images]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/transformers/models/clip/image_processing_clip.py", line 282, in <listcomp>
    images = [to_numpy_array(image) for image in images]
              ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/transformers/image_utils.py", line 156, in to_numpy_array
    return np.array(img)
           ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/PIL/Image.py", line 686, in __array_interface__
    @property
KeyboardInterrupt