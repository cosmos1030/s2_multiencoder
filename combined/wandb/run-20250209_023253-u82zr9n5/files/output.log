
[INFO] Resume from checkpoint: ./checkpoints/cifar100/both_s2_transformer/best_epoch_1.pth
Epoch [2/10]





















































































































































































































































































































































































































































































Validating:  99%|███████████████████████████████████████████████████████████████████████████████████████████▊ | 78/79 [24:59<00:19, 19.08s/it]
  Train Loss: 0.3503 | Train Acc: 0.8977

Training:   0%|                                                                                                       | 0/391 [00:00<?, ?it/s]
 [*] Val loss improved. Checkpoint saved to ./checkpoints/cifar100/both_s2_transformer/best_epoch_2.pth















Traceback (most recent call last):
  File "/notebooks/s2_multiencoder/combined/main.py", line 215, in <module>
    main()
  File "/notebooks/s2_multiencoder/combined/main.py", line 153, in main
    best_ckpt = train_dual_encoder_probe(
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/notebooks/s2_multiencoder/combined/train.py", line 80, in train_dual_encoder_probe
    optimizer.step()
  File "/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py", line 163, in step
    adam(
  File "/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py", line 311, in adam
    func(params,
  File "/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py", line 551, in _multi_tensor_adam
    bias_correction1 = [1 - beta1 ** _get_value(step) for step in device_state_steps]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py", line 551, in <listcomp>
    bias_correction1 = [1 - beta1 ** _get_value(step) for step in device_state_steps]
                                     ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py", line 89, in _get_value
    return x.item()
           ^^^^^^^^
KeyboardInterrupt